{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge/Pull Request Checklist\n",
    "\n",
    "* For the csv files in the **Resources** folder, dont commit the zip files or the extracted csv files.\n",
    "* Make sure to restart and clear output in jupyter notebook.\n",
    "* Code is documented and includes comments.\n",
    "* Make sure you are working in your PythonData environment when making changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks and Timeline\n",
    "\n",
    "* Update the status of the tasks on the team [Trello Board](https://trello.com/b/qjMY63WI/whos-doing-what) so we know who is working on what."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started and Setup\n",
    "\n",
    "* **Team Lead** for this section: Phil\n",
    "* Before running these cells, you will need an API key for using YouTube API v3.\n",
    "    * If you already have a Google API key, you can use that one or create a new one from the Google Cloud Console.\n",
    "    * Instructions for creating an API key and enabling YouTube API v3 are in the [README file](./README.md).\n",
    "    * After you have your API key, create a file called **config.py** in the project root directory (**team_hopper**) where you will add the key.\n",
    "* After you have your API key set up, run the cells in this section to set up the project locally on your computer.\n",
    "* Running these cells will:\n",
    "    * Import the necessary dependencies, including reading the YouTube API key from the config.py file.\n",
    "    * Extract the data zip files in the **Resources** folder, which contains all of the csv files needed for this project.\n",
    "    * Import the csv files into this notebook.\n",
    "    * Read the csv files into pandas dataframes.\n",
    "* Questions or issues with the setup instructions, ask phil.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dependencies used for this project.\n",
    "import pandas as pd\n",
    "import requests\n",
    "from config import youtube_api_key\n",
    "from pprint import pprint\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os, zipfile\n",
    "import shutil\n",
    "import glob\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import matplotlib.colors as mcolors\n",
    "from datetime import datetime\n",
    "from itertools import cycle, islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the country codes to instruct the YouTube API\n",
    "# to return the list of video categories available in the specified country.\n",
    "# These values are ISO 3166-1 alpha-2 country codes.\n",
    "country_codes = [\"US\", \"GB\", \"CA\", \"DE\", \"FR\", \"AU\", \"IE\",\"IN\", \"JP\", \"KR\", \"MX\", \"RU\", \"ES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this cell will unzip the data files in the Resources folder for you.\n",
    "extension = \".zip\"\n",
    "extracted_dir_name = \"youtube_trending\"\n",
    "\n",
    "# Get the current working directory..\n",
    "# You need to be in the root directory of this project (same directory as this notebook) for this to work properly.\n",
    "cwd_dir_name = os.getcwd()\n",
    "print(f\"The current working directory is {cwd_dir_name}.\")\n",
    "\n",
    "os.chdir(\"Resources\") # change directory from working dir to dir with the zip file(s) .\n",
    "# This should be your \"Resources\" folder.\n",
    "dir_name = os.getcwd()\n",
    "print(f\"You are now in the following directory: {dir_name}.\")\n",
    "\n",
    "for item in os.listdir(dir_name): # loop through the items in the directory.\n",
    "    if item.endswith(extension): # check for \".zip\" extension\n",
    "        if item == \"youtube_trending.zip\":\n",
    "            extracted_dir_name = \"youtube_trending\"\n",
    "        if item == \"trending_videos_2020.zip\":\n",
    "            extracted_dir_name = \"trending_videos_2020\"\n",
    "        try:\n",
    "            file_name = os.path.abspath(item) # get full path of files\n",
    "            zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "            # Check if the directory where we plan to extract the files already exists or not.\n",
    "            if not os.path.exists(extracted_dir_name):\n",
    "                os.mkdir(extracted_dir_name) # make a directory where the zip files will be extracted.\n",
    "            unzipped_directory = os.path.join(extracted_dir_name) # reference to the directory where the zip files will be extracted.\n",
    "            zip_ref.extractall(unzipped_directory) # extract file to dir\n",
    "            zip_ref.close() # close file\n",
    "            print(f\"Successfully unzipped youtube data files into the following folder: {unzipped_directory} inside of {dir_name}.\")\n",
    "        except:\n",
    "            print(f\"Error trying to unzip youtube data file(s).\")\n",
    "            \n",
    "# Go up one directory into the project root directory.\n",
    "os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir))\n",
    "print(os.path.normpath(os.getcwd() + os.sep + os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the csv files from the trending youtube video statistics kaggle dataset.\n",
    "path_to_youtube_trending_csvs = os.path.join(\".\", \"Resources\", \"youtube_trending\")\n",
    "all_files = glob.glob(os.path.join(path_to_youtube_trending_csvs, \"*.csv\"))\n",
    "\n",
    "df_from_each_file = []\n",
    "\n",
    "for f in all_files:\n",
    "    filename = os.path.basename(f)\n",
    "    df_country = pd.read_csv(f, encoding =\"ISO-8859-1\")\n",
    "    df_country[\"Country\"] = f\"{filename[0]}{filename[1]}\"\n",
    "    df_from_each_file.append(df_country)\n",
    "\n",
    "# Concantenated dataframe that contains all countries.\n",
    "# Can filter list by country using the \"Country\" column\n",
    "trending_videos_concatenated_df = pd.concat(df_from_each_file, ignore_index=True)\n",
    "trending_videos_concatenated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to get the list of video categories from the YouTube API,\n",
    "# which can be associated with youtube videos by category id.\n",
    "def getVideoCategories(country_code):    \n",
    "    base_url_categories = \"https://www.googleapis.com/youtube/v3/videoCategories\"\n",
    "    part_categories = \"snippet\"\n",
    "    query_url_categories = f\"{base_url_categories}?part={part_categories}&regionCode={country_code}&key={youtube_api_key}\"\n",
    "    categories_response = requests.get(query_url_categories).json()\n",
    "    category_items = categories_response[\"items\"]\n",
    "    categories = []\n",
    "    \n",
    "    for category in category_items:\n",
    "        categories_dict = {}\n",
    "        categories_dict[\"category_id\"] = category[\"id\"]\n",
    "        categories_dict[\"channel_id\"] = category[\"snippet\"][\"channelId\"]\n",
    "        categories_dict[\"title\"] = category[\"snippet\"][\"title\"]\n",
    "        categories.append(categories_dict)\n",
    "    return categories\n",
    "\n",
    "for country in country_codes:\n",
    "    categories = []\n",
    "    categories = getVideoCategories(country)\n",
    "    categories_df = pd.DataFrame(categories)\n",
    "    output_file = f\"{country}_categories.csv\"\n",
    "    output_dir = Path(\"./Resources/categories\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    categories_df.to_csv(output_dir / output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the csv files that list the different categories.\n",
    "path_to_categories_csvs = os.path.join(\".\", \"Resources\", \"categories\")\n",
    "all_category_files = glob.glob(os.path.join(path_to_categories_csvs, \"*.csv\"))\n",
    "\n",
    "df_from_each_categories_file = []\n",
    "\n",
    "for f in all_category_files:\n",
    "    filename = os.path.basename(f)\n",
    "    df_categories = pd.read_csv(f, encoding =\"ISO-8859-1\")\n",
    "    df_categories[\"Country\"] = f\"{filename[0]}{filename[1]}\"\n",
    "    df_from_each_categories_file.append(df_categories)\n",
    "\n",
    "# Concantenated dataframe that contains all categories\n",
    "# Can filter list by country using the \"Country\" column\n",
    "categories_concatenated_df = pd.concat(df_from_each_categories_file, ignore_index=True)\n",
    "\n",
    "# Merge the dataframe of trending videos with the dataframe of categories on category_id and on country.\n",
    "merged_trending_df = pd.merge(trending_videos_concatenated_df, categories_concatenated_df,  how='left', left_on=['category_id','Country'], right_on = ['category_id','Country'], suffixes=(\"_video\", \"_category\"))\n",
    "\n",
    "merged_trending_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These csv files are YouTube's most popular videos for 2020.\n",
    "\n",
    "# Path to the csv files.\n",
    "path_to_trending_2020_csvs = os.path.join(\".\", \"Resources\", \"trending_videos_2020\")\n",
    "all_files_2020 = glob.glob(os.path.join(path_to_trending_2020_csvs, \"*.csv\"))\n",
    "\n",
    "df_from_each_file_2020 = []\n",
    "\n",
    "for f in all_files_2020:\n",
    "    filename = os.path.basename(f)\n",
    "    df_country = pd.read_csv(f, encoding =\"ISO-8859-1\")\n",
    "    df_country[\"Country\"] = f\"{filename[0]}{filename[1]}\"\n",
    "    df_from_each_file_2020.append(df_country)\n",
    "\n",
    "# Concantenated dataframe that contains all countries.\n",
    "# Can filter list by country using the \"Country\" column\n",
    "trending_2020_concatenated_df = pd.concat(df_from_each_file_2020, ignore_index=True)\n",
    "trending_2020_concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the csv files that list the different categories.\n",
    "path_to_categories_csvs = os.path.join(\".\", \"Resources\", \"categories\")\n",
    "all_category_files = glob.glob(os.path.join(path_to_categories_csvs, \"*.csv\"))\n",
    "\n",
    "df_from_each_categories_file = []\n",
    "\n",
    "for f in all_category_files:\n",
    "    filename = os.path.basename(f)\n",
    "    df_categories = pd.read_csv(f, encoding =\"ISO-8859-1\")\n",
    "    df_categories[\"Country\"] = f\"{filename[0]}{filename[1]}\"\n",
    "    df_from_each_categories_file.append(df_categories)\n",
    "\n",
    "# Concantenated dataframe that contains all categories\n",
    "# Can filter list by country using the \"Country\" column\n",
    "categories_concatenated_df = pd.concat(df_from_each_categories_file, ignore_index=True)\n",
    "\n",
    "# Merge the dataframe of trending videos with the dataframe of categories on category_id and on country.\n",
    "merged_trending_2020_df = pd.merge(trending_2020_concatenated_df, categories_concatenated_df,  how='left', left_on=['category_id','Country'], right_on = ['category_id','Country'], suffixes=(\"_video\", \"_category\"))\n",
    "\n",
    "merged_trending_2020_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving a list of YouTube's most popular videos\n",
    "\n",
    "* The following function retrieves a list of YouTube's most popular videos using version 3 of the YouTube API.\n",
    "* The API is updated daily to return the list of trending videos, which can be found on YouTube's site [here](https://www.youtube.com/feed/trending).\n",
    "* The function takes a country code as input, which identifies the country for which you are retrieving videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrendingVideos(country_code):\n",
    "    # The base api url for the youtube data api.\n",
    "    base_url = \"https://www.googleapis.com/youtube/v3/videos\"\n",
    "\n",
    "    # The page token identifies a specific page the API should return.\n",
    "    next_page_token=\"&\"\n",
    "\n",
    "    # Comma separated list of one or more video resource properties that the API response will include.\n",
    "    part = \"snippet,contentDetails,statistics\"\n",
    "\n",
    "    # The chart that you want to retrieve.\n",
    "    # mostPopular - returns the most popular (trending) videos.\n",
    "    chart = \"mostPopular\"\n",
    "\n",
    "    # The max results that should be returned in the list. Can return up to 50 results per page.\n",
    "    max_results = 50\n",
    "\n",
    "    # Create variable to store list of trending videos.\n",
    "    videos = []\n",
    "\n",
    "    while next_page_token is not None:\n",
    "        print(f\"One sec... getting trending videos for {country_code}....\")\n",
    "        query_url = f\"{base_url}?part={part}{next_page_token}chart={chart}&key={youtube_api_key}&maxResults={max_results}&regionCode={country_code}\"\n",
    "        trending_videos_response = requests.get(query_url).json()\n",
    "        trending_videos = trending_videos_response[\"items\"]\n",
    "        for video in trending_videos:\n",
    "            snippet = video[\"snippet\"]\n",
    "            contentDetails = video[\"contentDetails\"]\n",
    "            statistics = video[\"statistics\"]\n",
    "\n",
    "            video_dict = {}\n",
    "\n",
    "             # Fetch the id of the video.\n",
    "            video_dict[\"video_id\"] = video[\"id\"]\n",
    "\n",
    "            # The date the video was on youtube's trending list.\n",
    "            video_dict[\"trending_date\"] = time.strftime(\"%y.%d.%m\")\n",
    "\n",
    "            # Fetch video content details\n",
    "            # duration - the property value is an ISO 8601 duration. \n",
    "            video_dict[\"duration\"] = contentDetails[\"duration\"]\n",
    "            video_dict[\"captions_available\"] = contentDetails[\"caption\"]\n",
    "\n",
    "            # Fetch basic details about the video (snippet).\n",
    "            video_dict[\"title\"] = snippet[\"title\"]\n",
    "            video_dict[\"description\"] = snippet[\"description\"]\n",
    "            video_dict[\"publish_time\"] = snippet[\"publishedAt\"]\n",
    "            video_dict[\"category_id\"] = snippet[\"categoryId\"]\n",
    "            video_dict[\"channel_id\"] = snippet[\"channelId\"]\n",
    "            video_dict[\"channel_title\"] = snippet[\"channelTitle\"]\n",
    "            video_dict[\"localized_description\"] = snippet[\"localized\"][\"description\"]\n",
    "            video_dict[\"localized_title\"] = snippet[\"localized\"][\"title\"]\n",
    "            video_dict[\"live_broadcast_content\"] = snippet[\"liveBroadcastContent\"]\n",
    "            try:\n",
    "                video_dict[\"tags\"] = snippet[\"tags\"]\n",
    "            except KeyError:\n",
    "                video_dict[\"tags\"] = []\n",
    "            video_dict[\"thumbnail_link\"] = snippet[\"thumbnails\"][\"default\"][\"url\"]\n",
    "\n",
    "            # Fetch video statistics.\n",
    "            video_dict[\"comments_disabled\"] = False\n",
    "            try:\n",
    "                video_dict[\"comment_count\"] = statistics[\"commentCount\"]\n",
    "            except KeyError:\n",
    "                video_dict[\"comment_count\"] = 0\n",
    "                video_dict[\"comments_disabled\"] = True\n",
    "            ratings_disabled = False\n",
    "            try:\n",
    "                video_dict[\"dislikes\"] = statistics[\"dislikeCount\"] \n",
    "                video_dict[\"likes\"] = statistics[\"likeCount\"]\n",
    "            except KeyError:\n",
    "                video_dict[\"dislikes\"] = 0\n",
    "                video_dict[\"likes\"] = 0\n",
    "                ratings_disabled = True\n",
    "            video_dict[\"favorites\"] = statistics[\"favoriteCount\"]    \n",
    "            video_dict[\"views\"] = statistics[\"viewCount\"]\n",
    "\n",
    "            videos.append(video_dict)\n",
    "\n",
    "        # Check the nextPageToken on the API response to see if there is another page to fetch data from.\n",
    "        try:\n",
    "            next_page_token = trending_videos_response[\"nextPageToken\"]\n",
    "            next_page_token = f\"&pageToken={next_page_token}&\"\n",
    "        except KeyError:\n",
    "            next_page_token = None\n",
    "            \n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this cell retrieves the most popular videos for each country using the YouTube API and stores the output\n",
    "# in the Resources folder.\n",
    "# You do NOT need to run this cell.\n",
    "for country in country_codes:\n",
    "    country_videos = []\n",
    "    country_videos = getTrendingVideos(country)\n",
    "    country_videos_df = pd.DataFrame(country_videos)\n",
    "    # Leave the below lines commented out.\n",
    "    # output_file = f\"{country}_videos.csv\"\n",
    "    # output_dir = Path(\"./Resources/trending_videos_2020\")\n",
    "    # output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # country_videos_df.to_csv(output_dir / output_file, index=False, header=False, mode=\"a\")\n",
    "\n",
    "country_videos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell zips up the csv data files in \"Resources/trending_videos_2020\"\n",
    "# You do NOT need to run this.\n",
    "# dir_name = Path(\"./Resources/trending_videos_2020\")\n",
    "# shutil.make_archive(\"./Resources/trending_videos_2020\", 'zip', dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Data\n",
    "\n",
    "* **Team Lead** for this section: Jenna\n",
    "* Check for null/na values. Remove (if necessary).\n",
    "* Rename columns to be something more meaningful (remove underscores from column names).\n",
    "    * For example, change \"category_id\" to \"Category ID\".\n",
    "* Remove unnecessary columns.\n",
    "* As an additional resource, check out [this file](https://umn.bootcampcontent.com/University-of-Minnesota-Boot-Camp/UofM-STP-DATA-PT-11-2019-U-C/blob/master/04-Pandas/Activities/2019-12-16_and_17_Pandas_lesson_2/03-Ins_CleaningData/Solved/CleaningData.ipynb).\n",
    "* Do anything else that you think will make the data easy to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trending_df = merged_trending_df[['video_id', 'trending_date', 'title_video', 'channel_title', \n",
    "                                        'publish_time', 'tags', 'views', 'likes', 'dislikes', \"comment_count\",\n",
    "                                        'Country', 'title_category']]\n",
    "clean_trending_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trending_df = clean_trending_df.rename(columns = \n",
    "                                             {\"video_id\": \"Video ID\", \n",
    "                                              \"trending_date\": \"Trending Date\",\n",
    "                                             \"title_video\": \"Video Title\", \n",
    "                                             \"channel_title\":\"Channel Title\", \n",
    "                                             \"publish_time\": \"Publish Time\",\n",
    "                                             \"tags\": \"Tags\",\n",
    "                                             \"views\": \"Views\", \n",
    "                                              \"likes\": \"Likes\",\n",
    "                                             \"dislikes\": \"Dislikes\",\n",
    "                                             \"comment_count\": \"Comment Count\",\n",
    "                                             \"description\": \"Description\", \n",
    "                                             \"title_category\": \"Category\"})\n",
    "clean_trending_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for N/As\n",
    "clean_trending_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_trending_df['Category'].unique()\n",
    "#if time figure out what nan is\n",
    "clean_trending_df.dropna(how='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trending_df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_concatenated_df['title'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "* **Team Lead** for this section: Katrina\n",
    "* Perform a .describe() on the dataframe to get some quick summary statistics.\n",
    "* Calculate the mean, median, standard deviation, variance, and standard error of mean (sem) for trending videos.\n",
    "  * Do this for the numeric columns: views, likes, and comments.\n",
    "  * Might be also a good idea to group the dataframe by category id and calculate those same statistics.\n",
    "* As an additional resource, check out [this file](https://umn.bootcampcontent.com/University-of-Minnesota-Boot-Camp/UofM-STP-DATA-PT-11-2019-U-C/blob/master/05-Matplotlib/Activities/2020-01-06_and_07_lesson_3/01-Ins_Summary_Statistics/Solved/samples.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What type of categories are more likely to make it on the trending list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find US trending videos.\n",
    "us_category_groupby_df = clean_trending_df.loc[clean_trending_df[\"Country\"] == \"US\"]\n",
    "# Find OUS trending videos.\n",
    "ous_category_groupby_df = clean_trending_df.loc[clean_trending_df[\"Country\"] != \"US\"]\n",
    "\n",
    "# Group dataframe by category and count up number of videos.\n",
    "# Use .nunique so we don't count videos more than once.\n",
    "us_category_groupby_df = us_category_groupby_df.groupby(['Category'])['Video ID'].nunique().sort_values(ascending=False)\n",
    "us_category_groupby_df = pd.DataFrame(us_category_groupby_df)\n",
    "ous_category_groupby_df = ous_category_groupby_df.groupby(['Category'])['Video ID'].nunique().sort_values(ascending=False)\n",
    "ous_category_groupby_df = pd.DataFrame(ous_category_groupby_df)\n",
    "\n",
    "# Rename column to be something more meaningful.\n",
    "us_category_groupby_df = us_category_groupby_df.rename(columns={\n",
    "    \"Video ID\": \"Number of Trending Videos\"\n",
    "})\n",
    "ous_category_groupby_df = ous_category_groupby_df.rename(columns={\n",
    "    \"Video ID\": \"Number of Trending Videos\"\n",
    "})\n",
    "\n",
    "# Get the top 5 trending categories.\n",
    "top_5_categories_us = us_category_groupby_df[:5]\n",
    "top_5_categories_us = pd.DataFrame(top_5_categories_us)\n",
    "top_5_categories_ous = ous_category_groupby_df[:5]\n",
    "top_5_categories_ous = pd.DataFrame(top_5_categories_ous)\n",
    "\n",
    "# Get the other categories.\n",
    "new_row_us = pd.DataFrame({\n",
    "    'Category' : ['Others'],\n",
    "    'Number of Trending Videos' : [us_category_groupby_df['Number of Trending Videos'][5:].sum()]\n",
    "}).set_index(\"Category\")\n",
    "new_row_ous = pd.DataFrame({\n",
    "    'Category' : ['Others'],\n",
    "    'Number of Trending Videos' : [ous_category_groupby_df['Number of Trending Videos'][5:].sum()]\n",
    "}).set_index(\"Category\")\n",
    "\n",
    "# Combined the top 5 with the others.\n",
    "top_trending_categories_us = pd.concat([top_5_categories_us, new_row_us])\n",
    "top_trending_categories_ous = pd.concat([top_5_categories_ous, new_row_ous])\n",
    "\n",
    "# Print the results.\n",
    "print('-------------------------------------------------------')\n",
    "print('Top trending videos by category for OUS')\n",
    "print(top_trending_categories_ous)\n",
    "print('-------------------------------------------------------')\n",
    "print('Top trending videos by category for US')\n",
    "print(top_trending_categories_us)\n",
    "print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top trending videos by category for US and OUS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two pie charts. One that shows the top trending videos by category for US. Other for OUS (Outside of US).\n",
    "# The colors of each section of the pie chart.\n",
    "# OUS\n",
    "number_of_colors_ous = len(top_trending_categories_ous)\n",
    "colors_ous = random.choices(list(mcolors.TABLEAU_COLORS.values()),k = number_of_colors_ous)\n",
    "# US\n",
    "number_of_colors_us = len(top_trending_categories_us)\n",
    "colors_us = random.choices(list(mcolors.BASE_COLORS.values()),k = number_of_colors_us)\n",
    "\n",
    "# Specify the sizes and labels for the pie chart.\n",
    "# OUS\n",
    "sizes_ous = list(top_trending_categories_ous.loc[:, \"Number of Trending Videos\"])\n",
    "labels_ous = list(top_trending_categories_ous.index.values)\n",
    "# US\n",
    "sizes_us = list(top_trending_categories_us.loc[:, \"Number of Trending Videos\"])\n",
    "labels_us = list(top_trending_categories_us.index.values)\n",
    "\n",
    "# Creat plot for OUS.\n",
    "plt.figure(0)\n",
    "\n",
    "# explosion\n",
    "explode = (0.07,0,0,0,0,0)\n",
    "\n",
    "# Create pie chart.\n",
    "plt.pie(sizes_ous, colors=colors_ous, labels=labels_ous, autopct='%1.1f%%', startangle=90,  pctdistance=1.2, labeldistance=1.4, explode=explode, shadow=True)\n",
    "\n",
    "# Make a donut chart.\n",
    "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "# Equal axis\n",
    "plt.axis('equal') \n",
    "\n",
    "# Add a title.\n",
    "plt.title(\"Top Trending Videos By Category (OUS)\")\n",
    "\n",
    "# Add a legend.\n",
    "plt.legend(bbox_to_anchor=(1.025,1.10), loc=\"upper left\")\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(\"./Images/top_trending_videos_by_category_ous.png\", bbox_inches='tight')\n",
    "\n",
    "# Create plot for US.\n",
    "plt.figure(1)\n",
    "\n",
    "# explosion\n",
    "explode = (0.07,0,0,0,0,0)\n",
    "\n",
    "# Create pie chart.\n",
    "plt.pie(sizes_us, colors=colors_us, labels=labels_us, autopct='%1.1f%%', startangle=90,  pctdistance=1.2, labeldistance=1.4, explode=explode, shadow=True)\n",
    "\n",
    "# Make a donut chart.\n",
    "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "# Equal axis\n",
    "plt.axis('equal') \n",
    "\n",
    "# Add a title.\n",
    "plt.title(\"Top Trending Videos By Category (US)\")\n",
    "\n",
    "# Add a legend.\n",
    "plt.legend(bbox_to_anchor=(1.025,1.10), loc=\"upper left\")\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(\"./Images/top_trending_videos_by_category_us.png\", bbox_inches='tight')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does publish time affect engagement (number of likes and comments) and a video's chances of making it on the trending list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find US countries.\n",
    "us_publish_time_df = clean_trending_df.loc[clean_trending_df[\"Country\"] == \"US\"]\n",
    "# Find OUS countries.\n",
    "ous_publish_time_df = clean_trending_df.loc[clean_trending_df[\"Country\"] != \"US\"]\n",
    "\n",
    "# Only include columns we need.\n",
    "us_publish_time_df = us_publish_time_df[[\"Video ID\", \"Likes\", \"Comment Count\", \"Publish Time\"]]\n",
    "ous_publish_time_df = ous_publish_time_df[[\"Video ID\", \"Likes\", \"Comment Count\", \"Publish Time\"]]\n",
    "\n",
    "# Calculate total number of comments and likes for each video.\n",
    "# US\n",
    "total_number_likes_comments_us = (us_publish_time_df[\"Likes\"] + us_publish_time_df[\"Comment Count\"])\n",
    "us_publish_time_df[\"Total Number of Likes and Comments\"] = total_number_likes_comments_us\n",
    "# OUS\n",
    "total_number_likes_comments_ous = (ous_publish_time_df[\"Likes\"] + ous_publish_time_df[\"Comment Count\"])\n",
    "ous_publish_time_df[\"Total Number of Likes and Comments\"] = total_number_likes_comments_ous\n",
    "\n",
    "# Time Conversion\n",
    "# US\n",
    "us_publish_time_df[\"Publish Time\"] = pd.to_datetime(us_publish_time_df['Publish Time'], dayfirst=True).dt.strftime('%I:%M %p')\n",
    "us_publish_time_df[\"Publish Time\"] = pd.to_datetime(us_publish_time_df[\"Publish Time\"])\n",
    "# OUS\n",
    "ous_publish_time_df[\"Publish Time\"] = pd.to_datetime(ous_publish_time_df['Publish Time'], dayfirst=True).dt.strftime('%I:%M %p')\n",
    "ous_publish_time_df[\"Publish Time\"] = pd.to_datetime(ous_publish_time_df[\"Publish Time\"])\n",
    "\n",
    "hours = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "us_publish_time_df = us_publish_time_df.set_index(\"Publish Time\")\n",
    "ous_publish_time_df = ous_publish_time_df.set_index(\"Publish Time\")\n",
    "\n",
    "# Function to get average number of likes and comments for videos within specific ranges of time (i.e., 1 hour).\n",
    "def binTime(times, df):\n",
    "    number_likes_comments_time_of_day = []\n",
    "    number_trending_videos_time_of_day = []\n",
    "    for time in times:\n",
    "        time_bin = df.between_time(f'{time}:00', f'{time}:59')\n",
    "        average_comments_likes = time_bin[\"Total Number of Likes and Comments\"].mean()\n",
    "        number_trending_videos = time_bin[\"Video ID\"].nunique()\n",
    "        number_likes_comments_time_of_day.append(average_comments_likes)\n",
    "        number_trending_videos_time_of_day.append(number_trending_videos)\n",
    "    return number_likes_comments_time_of_day, number_trending_videos_time_of_day\n",
    "\n",
    "us_number_likes_comments, us_trending_videos_time_of_day = binTime(hours, us_publish_time_df)\n",
    "ous_number_likes_comments, ous_trending_videos_time_of_day = binTime(hours, ous_publish_time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create values/bins for x-axis. X-axis labels will be hour increments.\n",
    "x_axis = ['12 am', '1 am', '2 am', '3 am', '4 am', '5 am', '6 am', '7 am', '8 am',\n",
    "          '9 am', '10 am', '11 am', '12 pm', '1 pm', '2 pm', '3 pm', '4 pm', '5 pm',\n",
    "          '6 pm', '7 pm', '8 pm', '9 pm', '10 pm', '11 pm']\n",
    "\n",
    "# Put time of day, average number of likes and comments, and number of trending videos into a dataframe.\n",
    "us_time_of_day_df = pd.DataFrame({\n",
    "    \"Time of Day\": x_axis,\n",
    "    \"Average Number of Likes and Comments\": us_number_likes_comments,\n",
    "    \"Number of Trending Videos\": us_trending_videos_time_of_day\n",
    "})\n",
    "\n",
    "# Set index to time of day (this will be the x axis).\n",
    "us_time_of_day_df = us_time_of_day_df.set_index(\"Time of Day\")\n",
    "\n",
    "# Create matplotlib figure\n",
    "fig = plt.figure()\n",
    "\n",
    "# Create matplotlib axes\n",
    "ax = fig.add_subplot(111)\n",
    "# Create another axes that shares the same x-axis as ax.\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# Set the background color of the plot.\n",
    "ax.set_facecolor('#A5ACAF35')\n",
    "\n",
    "# Set the width of the bars.\n",
    "width = 0.4\n",
    "\n",
    "# Plot average number of likes and comments.\n",
    "us_time_of_day_df[\"Average Number of Likes and Comments\"].plot(kind='bar', ax=ax, width=width, position=1, figsize=(15,7), color='#002145', alpha=0.6)\n",
    "# Plot number of trending videos on the same plot.\n",
    "us_time_of_day_df[\"Number of Trending Videos\"].plot(kind='bar', ax=ax2, width=width, position=0,  color='#66C010', alpha=1.0)\n",
    "\n",
    "# Rotate the xtick labels.\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "\n",
    "# Give the plot a title.\n",
    "plt.title(\"(US) Average Number of Likes and Comments vs Number of Trending Videos at Different Times of Day\")\n",
    "\n",
    "# Add labels to y-axes.\n",
    "ax.set_ylabel('Average Number of Likes and Comments')\n",
    "ax2.set_ylabel('Number of Trending Videos')\n",
    "\n",
    "# Add legends.\n",
    "ax.legend([\"Average Number of Likes and Comments\"], loc=\"upper left\");\n",
    "ax2.legend([\"Number of Trending Videos\"], loc=\"upper right\");\n",
    "\n",
    "# Save figure as an image.\n",
    "plt.savefig(\"./Images/time_of_day_us.png\", bbox_inches='tight')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create values/bins for x-axis. X-axis labels will be hour increments.\n",
    "x_axis = ['12 am', '1 am', '2 am', '3 am', '4 am', '5 am', '6 am', '7 am', '8 am',\n",
    "          '9 am', '10 am', '11 am', '12 pm', '1 pm', '2 pm', '3 pm', '4 pm', '5 pm',\n",
    "          '6 pm', '7 pm', '8 pm', '9 pm', '10 pm', '11 pm']\n",
    "\n",
    "# Put time of day, average number of likes and comments, and number of trending videos into a dataframe.\n",
    "ous_time_of_day_df = pd.DataFrame({\n",
    "    \"Time of Day\": x_axis,\n",
    "    \"Average Number of Likes and Comments\": ous_number_likes_comments,\n",
    "    \"Number of Trending Videos\": ous_trending_videos_time_of_day\n",
    "})\n",
    "\n",
    "# Set index to time of day (this will be the x axis).\n",
    "ous_time_of_day_df = ous_time_of_day_df.set_index(\"Time of Day\")\n",
    "\n",
    "# Create matplotlib figure\n",
    "fig = plt.figure()\n",
    "\n",
    "# Create matplotlib axes\n",
    "ax = fig.add_subplot(111)\n",
    "# Create another axes that shares the same x-axis as ax.\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# Set the background color of the plot.\n",
    "ax.set_facecolor('#A5ACAF35')\n",
    "\n",
    "# Set the width of the bars.\n",
    "width = 0.4\n",
    "\n",
    "# Plot average number of likes and comments.\n",
    "ous_time_of_day_df[\"Average Number of Likes and Comments\"].plot(kind='bar', ax=ax, width=width, position=1, figsize=(15,7), color='#002145', alpha=0.6)\n",
    "# Plot number of trending videos on the same plot.\n",
    "ous_time_of_day_df[\"Number of Trending Videos\"].plot(kind='bar', ax=ax2, width=width, position=0,  color='#66C010', alpha=1.0)\n",
    "\n",
    "# Rotate the xtick labels.\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "\n",
    "# Give the plot a title.\n",
    "plt.title(\"(OUS) Average Number of Likes and Comments vs Number of Trending Videos at Different Times of Day\")\n",
    "\n",
    "# Add labels to y-axes.\n",
    "ax.set_ylabel('Average Number of Likes and Comments')\n",
    "ax2.set_ylabel('Number of Trending Videos')\n",
    "\n",
    "# Add legends.\n",
    "ax.legend([\"Average Number of Likes and Comments\"], loc=\"upper left\");\n",
    "ax2.legend([\"Number of Trending Videos\"], loc=\"upper right\");\n",
    "\n",
    "# Save figure as an image.\n",
    "plt.savefig(\"./Images/time_of_day_ous.png\", bbox_inches='tight')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

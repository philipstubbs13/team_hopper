{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge/Pull Request Checklist\n",
    "\n",
    "* For the csv files in the **Resources** folder, dont commit the zip files or the extracted csv files.\n",
    "* Make sure to restart and clear output in jupyter notebook.\n",
    "* Code is documented and includes comments.\n",
    "* Make sure you are working in your PythonData environment when making changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks and Timeline\n",
    "\n",
    "* Update the status of the tasks on the team [Trello Board](https://trello.com/b/qjMY63WI/whos-doing-what) so we know who is working on what."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "* **Team Lead** for this section: Katrina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started and Setup\n",
    "\n",
    "* [Import the dependencies used for this project](#dependencies)\n",
    "* [Import country codes](#country_codes)\n",
    "* [Unzip data files in Resources folder](#unzip_data_files)\n",
    "* [Import csv files and read into pandas dataframe](#import_csv_files)\n",
    "* [Mapping category id to category name](#category_mapping)\n",
    "* [Import csv files that include 2020 trending video data](#import_2020_data)\n",
    "* [Retrieving a list of YouTube's most popular videos using YouTube API v3](#retrieving_data)\n",
    "* [Getting data from YouTube API and saving it into country-specific csv files](#saving_data)\n",
    "* [Unzip the trending_videos_2020.zip file in the Resources folder](#unzip_2020_data)\n",
    "\n",
    "\n",
    "* **Notes**\n",
    "    * Before running these cells, you will need an API key for using YouTube API v3.\n",
    "    * If you already have a Google API key, you can use that one or create a new one from the Google Cloud Console.\n",
    "    * Instructions for creating an API key and enabling YouTube API v3 are in the [README file](./README.md).\n",
    "    * After you have your API key, create a file called **config.py** in the project root directory (**team_hopper**) where you will add the key.\n",
    "    * After you have your API key set up, run the cells in this section to set up the project locally on your computer.\n",
    "    * Running these cells will:\n",
    "        * Import the necessary dependencies, including reading the YouTube API key from the config.py file.\n",
    "        * Extract the data zip files in the **Resources** folder, which contains all of the csv files needed for this project.\n",
    "        * Import the csv files into this notebook.\n",
    "        * Read the csv files into pandas dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"dependencies\"></a> Import the dependencies used for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other\n",
    "import random\n",
    "from itertools import cycle, islice\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import scipy.stats as st\n",
    "\n",
    "# API key\n",
    "from config import youtube_api_key\n",
    "\n",
    "# Used for reading, writing to, and zipping files/folders.\n",
    "from pathlib import Path\n",
    "import os, zipfile\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# Used for formatting dates/times.\n",
    "from datetime import datetime\n",
    "import isodate\n",
    "import time\n",
    "\n",
    "# Matplotlib\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Ignore warnings - for presentation purposes only.\n",
    "# Dont import for development work.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"country_codes\"></a> Import country codes\n",
    "\n",
    "We need the country codes to instruct the YouTube API to return the list of video categories available in the specified country. These values are ISO 3166-1 alpha-2 country codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = [\"US\", \"GB\", \"CA\", \"DE\", \"FR\", \"AU\", \"IE\",\"IN\", \"JP\", \"KR\", \"MX\", \"RU\", \"ES\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"unzip_data_files\"></a> Unzip data files in Resources folder\n",
    "\n",
    "Running the following cell will extract the data zip files in the Resources folder, which contains all of the csv files needed for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this cell will unzip the data files in the Resources folder for you.\n",
    "extension = \".zip\"\n",
    "extracted_dir_name = \"youtube_trending\"\n",
    "\n",
    "# Get the current working directory..\n",
    "# You need to be in the root directory of this project (same directory as this notebook) for this to work properly.\n",
    "cwd_dir_name = os.getcwd()\n",
    "print(f\"The current working directory is {cwd_dir_name}.\")\n",
    "\n",
    "os.chdir(\"Resources\") # change directory from working dir to dir with the zip file(s) .\n",
    "# This should be your \"Resources\" folder.\n",
    "dir_name = os.getcwd()\n",
    "print(f\"You are now in the following directory: {dir_name}.\")\n",
    "\n",
    "for item in os.listdir(dir_name): # loop through the items in the directory.\n",
    "    if item.endswith(extension): # check for \".zip\" extension\n",
    "        if item == \"youtube_trending.zip\":\n",
    "            extracted_dir_name = \"youtube_trending\"\n",
    "        if item == \"trending_videos_2020.zip\":\n",
    "            extracted_dir_name = \"trending_videos_2020\"\n",
    "        try:\n",
    "            file_name = os.path.abspath(item) # get full path of files\n",
    "            zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "            # Check if the directory where we plan to extract the files already exists or not.\n",
    "            if not os.path.exists(extracted_dir_name):\n",
    "                os.mkdir(extracted_dir_name) # make a directory where the zip files will be extracted.\n",
    "            unzipped_directory = os.path.join(extracted_dir_name) # reference to the directory where the zip files will be extracted.\n",
    "            zip_ref.extractall(unzipped_directory) # extract file to dir\n",
    "            zip_ref.close() # close file\n",
    "            print(f\"Successfully unzipped youtube data files into the following folder: {unzipped_directory} inside of {dir_name}.\")\n",
    "        except:\n",
    "            print(f\"Error trying to unzip youtube data file(s).\")\n",
    "            \n",
    "# Go up one directory into the project root directory.\n",
    "os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir))\n",
    "print(os.path.normpath(os.getcwd() + os.sep + os.pardir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"import_csv_files\"></a> Import csv files and read into pandas dataframe \n",
    "\n",
    "Running the following cell will:\n",
    "* Find and take all of the csv files in **Resources/youtube_trending**.\n",
    "* Concatenate them into one dataframe.\n",
    "* Add a Country column by taking the country abbreviation in the file name.\n",
    "* Display the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the csv files from the trending youtube video statistics kaggle dataset.\n",
    "path_to_youtube_trending_csvs = os.path.join(\".\", \"Resources\", \"youtube_trending\")\n",
    "all_files = glob.glob(os.path.join(path_to_youtube_trending_csvs, \"*.csv\"))\n",
    "\n",
    "df_from_each_file = []\n",
    "\n",
    "for f in all_files:\n",
    "    filename = os.path.basename(f)\n",
    "    df_country = pd.read_csv(f, encoding =\"ISO-8859-1\")\n",
    "    df_country[\"Country\"] = f\"{filename[0]}{filename[1]}\"\n",
    "    df_from_each_file.append(df_country)\n",
    "\n",
    "# Concantenated dataframe that contains all countries.\n",
    "# Can filter list by country using the \"Country\" column\n",
    "trending_videos_concatenated_df = pd.concat(df_from_each_file, ignore_index=True)\n",
    "trending_videos_concatenated_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"category_mapping\"></a> Mapping category id to category name.\n",
    "\n",
    "The original dataset from kaggle we are using for this project only includes the category id for each trending video and does not include the name of the category. So, we created a function that makes a request to the YouTube API videoCategories endpoint to get all of the categories information for each country. After hitting the endpoint, we store the video category results in a separate .csv file for each country inside the **Resources/categories** folder. We then import that .csv file into a pandas dataframe and merge that dataframe with the original one so we have access to the category id as well as the actual name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to get the list of video categories from the YouTube API,\n",
    "# which can be associated with youtube videos by category id.\n",
    "def getVideoCategories(country_code):    \n",
    "    base_url_categories = \"https://www.googleapis.com/youtube/v3/videoCategories\"\n",
    "    part_categories = \"snippet\"\n",
    "    query_url_categories = f\"{base_url_categories}?part={part_categories}&regionCode={country_code}&key={youtube_api_key}\"\n",
    "    categories_response = requests.get(query_url_categories).json()\n",
    "    category_items = categories_response[\"items\"]\n",
    "    categories = []\n",
    "    \n",
    "    for category in category_items:\n",
    "        categories_dict = {}\n",
    "        categories_dict[\"category_id\"] = category[\"id\"]\n",
    "        categories_dict[\"channel_id\"] = category[\"snippet\"][\"channelId\"]\n",
    "        categories_dict[\"title\"] = category[\"snippet\"][\"title\"]\n",
    "        categories.append(categories_dict)\n",
    "    return categories\n",
    "\n",
    "for country in country_codes:\n",
    "    categories = []\n",
    "    categories = getVideoCategories(country)\n",
    "    categories_df = pd.DataFrame(categories)\n",
    "    output_file = f\"{country}_categories.csv\"\n",
    "    output_dir = Path(\"./Resources/categories\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    categories_df.to_csv(output_dir / output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the csv files that list the different categories.\n",
    "path_to_categories_csvs = os.path.join(\".\", \"Resources\", \"categories\")\n",
    "all_category_files = glob.glob(os.path.join(path_to_categories_csvs, \"*.csv\"))\n",
    "\n",
    "df_from_each_categories_file = []\n",
    "\n",
    "for f in all_category_files:\n",
    "    filename = os.path.basename(f)\n",
    "    df_categories = pd.read_csv(f, encoding =\"ISO-8859-1\")\n",
    "    df_categories[\"Country\"] = f\"{filename[0]}{filename[1]}\"\n",
    "    df_from_each_categories_file.append(df_categories)\n",
    "\n",
    "# Concantenated dataframe that contains all categories\n",
    "# Can filter list by country using the \"Country\" column\n",
    "categories_concatenated_df = pd.concat(df_from_each_categories_file, ignore_index=True)\n",
    "\n",
    "# Merge the dataframe of trending videos with the dataframe of categories on category_id and on country.\n",
    "merged_trending_df = pd.merge(trending_videos_concatenated_df, categories_concatenated_df,  how='left', left_on=['category_id','Country'], right_on = ['category_id','Country'], suffixes=(\"_video\", \"_category\"))\n",
    "\n",
    "merged_trending_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"import_2020_data\"></a> Import csv files that include 2020 trending video data\n",
    "\n",
    "In addition to using the kaggle dataset, which includes information about trending videos from 2017 - 2018, we also gathered more recent data on trending videos so far in 2020. We got this data using version 3 of the YouTube API and querying for most popular videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These csv files are YouTube's most popular videos for 2020.\n",
    "# Path to the csv files.\n",
    "path_to_trending_2020_csvs = os.path.join(\".\", \"Resources\", \"trending_videos_2020\")\n",
    "all_files_2020 = glob.glob(os.path.join(path_to_trending_2020_csvs, \"*.csv\"))\n",
    "\n",
    "df_from_each_file_2020 = []\n",
    "\n",
    "for f in all_files_2020:\n",
    "    filename = os.path.basename(f)\n",
    "    df_country = pd.read_csv(f, encoding =\"ISO-8859-1\")\n",
    "    df_country[\"Country\"] = f\"{filename[0]}{filename[1]}\"\n",
    "    df_from_each_file_2020.append(df_country)\n",
    "\n",
    "# Concantenated dataframe that contains all countries.\n",
    "# Can filter list by country using the \"Country\" column\n",
    "trending_2020_concatenated_df = pd.concat(df_from_each_file_2020, ignore_index=True)\n",
    "trending_2020_concatenated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the csv files that list the different categories.\n",
    "path_to_categories_csvs = os.path.join(\".\", \"Resources\", \"categories\")\n",
    "all_category_files = glob.glob(os.path.join(path_to_categories_csvs, \"*.csv\"))\n",
    "\n",
    "df_from_each_categories_file = []\n",
    "\n",
    "for f in all_category_files:\n",
    "    filename = os.path.basename(f)\n",
    "    df_categories = pd.read_csv(f, encoding =\"ISO-8859-1\")\n",
    "    df_categories[\"Country\"] = f\"{filename[0]}{filename[1]}\"\n",
    "    df_from_each_categories_file.append(df_categories)\n",
    "\n",
    "# Concantenated dataframe that contains all categories\n",
    "# Can filter list by country using the \"Country\" column\n",
    "categories_concatenated_df = pd.concat(df_from_each_categories_file, ignore_index=True)\n",
    "\n",
    "# Merge the dataframe of trending videos with the dataframe of categories on category_id and on country.\n",
    "merged_trending_2020_df = pd.merge(trending_2020_concatenated_df, categories_concatenated_df,  how='left', left_on=['category_id','Country'], right_on = ['category_id','Country'], suffixes=(\"_video\", \"_category\"))\n",
    "\n",
    "merged_trending_2020_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"retrieving_data\"></a> Retrieving a list of YouTube's most popular videos using YouTube API v3\n",
    "\n",
    "* The following function retrieves a list of YouTube's most popular videos using version 3 of the YouTube API.\n",
    "* The list of trending videos is updated roughly every 15 minutes. With each update, videos may move up, down, or stay in the same position in the list. For more information about trending on YouTube, go [here](https://support.google.com/youtube/answer/7239739?hl=en).\n",
    "* The list of trending videos can be found on YouTube's site [here](https://www.youtube.com/feed/trending).\n",
    "* The function takes a country code as input, which identifies the country for which you are retrieving videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrendingVideos(country_code):\n",
    "    # The base api url for the youtube data api.\n",
    "    base_url = \"https://www.googleapis.com/youtube/v3/videos\"\n",
    "\n",
    "    # The page token identifies a specific page the API should return.\n",
    "    next_page_token=\"&\"\n",
    "\n",
    "    # Comma separated list of one or more video resource properties that the API response will include.\n",
    "    part = \"snippet,contentDetails,statistics\"\n",
    "\n",
    "    # The chart that you want to retrieve.\n",
    "    # mostPopular - returns the most popular (trending) videos.\n",
    "    chart = \"mostPopular\"\n",
    "\n",
    "    # The max results that should be returned in the list. Can return up to 50 results per page.\n",
    "    max_results = 50\n",
    "\n",
    "    # Create variable to store list of trending videos.\n",
    "    videos = []\n",
    "\n",
    "    while next_page_token is not None:\n",
    "        print(f\"One sec... getting trending videos for {country_code}....\")\n",
    "        query_url = f\"{base_url}?part={part}{next_page_token}chart={chart}&key={youtube_api_key}&maxResults={max_results}&regionCode={country_code}\"\n",
    "        trending_videos_response = requests.get(query_url).json()\n",
    "        trending_videos = trending_videos_response[\"items\"]\n",
    "        for video in trending_videos:\n",
    "            snippet = video[\"snippet\"]\n",
    "            contentDetails = video[\"contentDetails\"]\n",
    "            statistics = video[\"statistics\"]\n",
    "\n",
    "            video_dict = {}\n",
    "\n",
    "             # Fetch the id of the video.\n",
    "            video_dict[\"video_id\"] = video[\"id\"]\n",
    "\n",
    "            # The date the video was on youtube's trending list.\n",
    "            video_dict[\"trending_date\"] = time.strftime(\"%y.%d.%m\")\n",
    "\n",
    "            # Fetch video content details\n",
    "            # duration - the property value is an ISO 8601 duration. \n",
    "            video_dict[\"duration\"] = contentDetails[\"duration\"]\n",
    "            video_dict[\"captions_available\"] = contentDetails[\"caption\"]\n",
    "\n",
    "            # Fetch basic details about the video (snippet).\n",
    "            video_dict[\"title\"] = snippet[\"title\"]\n",
    "            video_dict[\"description\"] = snippet[\"description\"]\n",
    "            video_dict[\"publish_time\"] = snippet[\"publishedAt\"]\n",
    "            video_dict[\"category_id\"] = snippet[\"categoryId\"]\n",
    "            video_dict[\"channel_id\"] = snippet[\"channelId\"]\n",
    "            video_dict[\"channel_title\"] = snippet[\"channelTitle\"]\n",
    "            video_dict[\"localized_description\"] = snippet[\"localized\"][\"description\"]\n",
    "            video_dict[\"localized_title\"] = snippet[\"localized\"][\"title\"]\n",
    "            video_dict[\"live_broadcast_content\"] = snippet[\"liveBroadcastContent\"]\n",
    "            try:\n",
    "                video_dict[\"tags\"] = snippet[\"tags\"]\n",
    "            except KeyError:\n",
    "                video_dict[\"tags\"] = []\n",
    "            video_dict[\"thumbnail_link\"] = snippet[\"thumbnails\"][\"default\"][\"url\"]\n",
    "\n",
    "            # Fetch video statistics.\n",
    "            video_dict[\"comments_disabled\"] = False\n",
    "            try:\n",
    "                video_dict[\"comment_count\"] = statistics[\"commentCount\"]\n",
    "            except KeyError:\n",
    "                video_dict[\"comment_count\"] = 0\n",
    "                video_dict[\"comments_disabled\"] = True\n",
    "            ratings_disabled = False\n",
    "            try:\n",
    "                video_dict[\"dislikes\"] = statistics[\"dislikeCount\"] \n",
    "                video_dict[\"likes\"] = statistics[\"likeCount\"]\n",
    "            except KeyError:\n",
    "                video_dict[\"dislikes\"] = 0\n",
    "                video_dict[\"likes\"] = 0\n",
    "                ratings_disabled = True\n",
    "            video_dict[\"favorites\"] = statistics[\"favoriteCount\"]    \n",
    "            video_dict[\"views\"] = statistics[\"viewCount\"]\n",
    "\n",
    "            videos.append(video_dict)\n",
    "\n",
    "        # Check the nextPageToken on the API response to see if there is another page to fetch data from.\n",
    "        try:\n",
    "            next_page_token = trending_videos_response[\"nextPageToken\"]\n",
    "            next_page_token = f\"&pageToken={next_page_token}&\"\n",
    "        except KeyError:\n",
    "            next_page_token = None\n",
    "            \n",
    "    return videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"saving_data\"></a> Getting data from YouTube API and saving it into country-specific csv files\n",
    "\n",
    "Running this cell will call the getTrendingVideos function above, which hits the YouTube API endpoint and gets the most popular videos. After the request is complete, the results will be saved to country-specific csv files in the **Resources/trending_videos_2020** folder and then imported into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this cell retrieves the most popular videos for each country using the YouTube API and stores the output\n",
    "# in the Resources folder.\n",
    "for country in country_codes:\n",
    "    country_videos = []\n",
    "    country_videos = getTrendingVideos(country)\n",
    "    country_videos_df = pd.DataFrame(country_videos)\n",
    "    # Leave the below lines commented out.\n",
    "    # output_file = f\"{country}_videos.csv\"\n",
    "    # output_dir = Path(\"./Resources/trending_videos_2020\")\n",
    "    # output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # country_videos_df.to_csv(output_dir / output_file, index=False, header=False, mode=\"a\")\n",
    "\n",
    "country_videos_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"unzip_2020_data\"></a> Unzip the trending_videos_2020.zip file in the Resources folder\n",
    "\n",
    "This step is for first time setup only to unzip/extract the trending_videos_2020.zip file into the **Resources** folder so that the csv files can be imported and read into pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell zips up the csv data files in \"Resources/trending_videos_2020\"\n",
    "# dir_name = Path(\"./Resources/trending_videos_2020\")\n",
    "# shutil.make_archive(\"./Resources/trending_videos_2020\", 'zip', dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Data\n",
    "\n",
    "* Check for null/na values. Remove (if necessary).\n",
    "* Rename columns to be something more meaningful (remove underscores from column names).\n",
    "    * For example, change \"category_id\" to \"Category ID\".\n",
    "* Remove unnecessary columns.\n",
    "* As an additional resource, check out [this file](https://umn.bootcampcontent.com/University-of-Minnesota-Boot-Camp/UofM-STP-DATA-PT-11-2019-U-C/blob/master/04-Pandas/Activities/2019-12-16_and_17_Pandas_lesson_2/03-Ins_CleaningData/Solved/CleaningData.ipynb).\n",
    "* Do anything else that you think will make the data easy to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trending_df = merged_trending_df[['video_id', 'trending_date', 'title_video', 'channel_title', \n",
    "                                        'publish_time', 'tags', 'views', 'likes', 'dislikes', \"comment_count\",\n",
    "                                        'Country', 'title_category']]\n",
    "clean_trending_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trending_df = clean_trending_df.rename(columns = \n",
    "                                             {\"video_id\": \"Video ID\", \n",
    "                                              \"trending_date\": \"Trending Date\",\n",
    "                                             \"title_video\": \"Video Title\", \n",
    "                                             \"channel_title\":\"Channel Title\", \n",
    "                                             \"publish_time\": \"Publish Time\",\n",
    "                                             \"tags\": \"Tags\",\n",
    "                                             \"views\": \"Views\", \n",
    "                                              \"likes\": \"Likes\",\n",
    "                                             \"dislikes\": \"Dislikes\",\n",
    "                                             \"comment_count\": \"Comment Count\",\n",
    "                                             \"description\": \"Description\", \n",
    "                                             \"title_category\": \"Category\"})\n",
    "clean_trending_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for N/As\n",
    "clean_trending_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_trending_df['Category'].unique()\n",
    "#if time figure out what nan is\n",
    "clean_trending_df.dropna(how='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trending_df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_concatenated_df['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean 2020 merged data\n",
    "clean_trending2020_df = merged_trending_2020_df[\n",
    "                                        ['video_id', 'trending_date', 'duration', 'title_video', 'channel_title', \n",
    "                                        'publish_time', 'tags', 'views', 'likes', 'dislikes', \n",
    "                                        'Country', 'title_category','comment_count']]\n",
    "clean_trending2020_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the 2020 merged data \n",
    "clean_trending_2020_df = clean_trending2020_df.rename(columns = \n",
    "                                             {\"video_id\": \"Video ID\", \n",
    "                                              \"trending_date\": \"Trending Date\",\n",
    "                                              \"duration\": \"Duration\",\n",
    "                                             \"title_video\": \"Video Title\", \n",
    "                                             \"channel_title\":\"Channel Title\", \n",
    "                                             \"publish_time\": \"Publish Time\",\n",
    "                                             \"tags\": \"Tags\",\n",
    "                                             \"views\": \"Views\", \n",
    "                                              \"likes\": \"Likes\",\n",
    "                                             \"dislikes\": \"Dislikes\",\n",
    "                                             \"description\": \"Description\", \n",
    "                                             \"title_category\": \"Category\",\n",
    "                                             \"comment_count\":\"Comment Count\"})\n",
    "clean_trending_2020_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look for NAN \n",
    "clean_trending_2020_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NAN\n",
    "clean_trending_2020_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trending_2020_df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trending_2020_df.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "* [Quick Summary Stats](#quick_summary_statistics)\n",
    "* [Summary of Views](#summary_of_views)\n",
    "* [Summary of Likes](#summary_of_likes)\n",
    "* [Summary of Dislikes](#summary_of_dislikes)\n",
    "* [Summary of Comment Count](#summary_of_comment_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"quick_summary_statistics\"></a> Quick Summary  Stats\n",
    "\n",
    "* Perform a .describe() on the dataframe to get some quick summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trending_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"summary_of_views\"></a> Summary of Views\n",
    "\n",
    "Calculate the mean, median, standard deviation, variance, and standard error of mean (sem) for views.\n",
    "As an additional resource, check out [this file](https://umn.bootcampcontent.com/University-of-Minnesota-Boot-Camp/UofM-STP-DATA-PT-11-2019-U-C/blob/master/05-Matplotlib/Activities/2020-01-06_and_07_lesson_3/01-Ins_Summary_Statistics/Solved/samples.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate summary stats for numeric columns in dataset/dataframe.\n",
    "def generateSummaryStats(column, df):\n",
    "    mean_numpy = np.mean(df[column])\n",
    "    median_numpy = np.median(df[column])\n",
    "    std_numpy = np.std(df[column])\n",
    "    var_numpy = np.var(df[column])\n",
    "    sem_numpy = df[column].sem()\n",
    "\n",
    "    summary_df = pd.DataFrame({ f\"Average Number of {column}\":round(mean_numpy,2),\n",
    "                                 f\"Median Number of {column}\":round(median_numpy,2),\n",
    "                                 f\"Standard Deviation of {column}\":round(mean_numpy,2),\n",
    "                                  f\"Variance of {column}\":round(median_numpy,2),\n",
    "                                 f\"Standard Error of Mean of {column}\":round(sem_numpy,2)},index = [0])\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "# Function to generate histogram\n",
    "def generateHistogram(column, df, number_bins, title):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.hist(df[column], bins=number_bins)\n",
    "    plt.xlabel(f'Number of {column}')\n",
    "    plt.ylabel('Number of Videos')\n",
    "    plt.title(title)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateSummaryStats(\"Views\", clean_trending_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterize the data set using histogram.\n",
    "generateHistogram(\"Views\", clean_trending_df, 20, title=\"Trending Video Views\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Videos with less than 2 million views.\n",
    "videos_with_less_2_million_views = clean_trending_df[clean_trending_df['Views'] < 2e6]\n",
    "generateHistogram(\"Views\", videos_with_less_2_million_views, 20, title=\"Less than 2 million views\")\n",
    "\n",
    "# Find out the percentage of trending videos with less than 2 million views.\n",
    "number_videos_with_less_2_million_views = videos_with_less_2_million_views[\"Video ID\"].count()\n",
    "total_number_videos = clean_trending_df[\"Video ID\"].count()\n",
    "percentage_of_videos_2_million = (number_videos_with_less_2_million_views / total_number_videos) * 100\n",
    "\n",
    "print(f\"The percentage of videos with less than 2 million views is {round(percentage_of_videos_2_million, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"summary_of_likes\"></a> Summary of Likes\n",
    "\n",
    "Calculate the mean, median, standard deviation, variance, and standard error of mean (sem) for likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateSummaryStats(\"Likes\", clean_trending_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"summary_of_dislikes\"></a> Summary of Dislikes\n",
    "\n",
    "Calculate the mean, median, standard deviation, variance, and standard error of mean (sem) for dislikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateSummaryStats(\"Dislikes\", clean_trending_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"summary_of_comment_count\"></a> Summary of Comment Count\n",
    "\n",
    "Calculate the mean, median, standard deviation, variance, and standard error of mean (sem) for comment count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateSummaryStats(\"Comment Count\", clean_trending_df)                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are certain types of categories more popular?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find US trending videos.\n",
    "us_category_groupby_df = clean_trending_df.loc[clean_trending_df[\"Country\"] == \"US\"]\n",
    "# Find OUS trending videos.\n",
    "ous_category_groupby_df = clean_trending_df.loc[clean_trending_df[\"Country\"] != \"US\"]\n",
    "\n",
    "# Group dataframe by category and count up number of videos.\n",
    "# Use .nunique so we don't count videos more than once.\n",
    "us_category_groupby_df = us_category_groupby_df.groupby(['Category'])['Video ID'].nunique().sort_values(ascending=False)\n",
    "us_category_groupby_df = pd.DataFrame(us_category_groupby_df)\n",
    "ous_category_groupby_df = ous_category_groupby_df.groupby(['Category'])['Video ID'].nunique().sort_values(ascending=False)\n",
    "ous_category_groupby_df = pd.DataFrame(ous_category_groupby_df)\n",
    "\n",
    "# Rename column to be something more meaningful.\n",
    "us_category_groupby_df = us_category_groupby_df.rename(columns={\n",
    "    \"Video ID\": \"Number of Trending Videos\"\n",
    "})\n",
    "ous_category_groupby_df = ous_category_groupby_df.rename(columns={\n",
    "    \"Video ID\": \"Number of Trending Videos\"\n",
    "})\n",
    "\n",
    "# Get the top 5 trending categories.\n",
    "top_5_categories_us = us_category_groupby_df[:5]\n",
    "top_5_categories_us = pd.DataFrame(top_5_categories_us)\n",
    "top_5_categories_ous = ous_category_groupby_df[:5]\n",
    "top_5_categories_ous = pd.DataFrame(top_5_categories_ous)\n",
    "\n",
    "# Get the other categories.\n",
    "new_row_us = pd.DataFrame({\n",
    "    'Category' : ['Others'],\n",
    "    'Number of Trending Videos' : [us_category_groupby_df['Number of Trending Videos'][5:].sum()]\n",
    "}).set_index(\"Category\")\n",
    "new_row_ous = pd.DataFrame({\n",
    "    'Category' : ['Others'],\n",
    "    'Number of Trending Videos' : [ous_category_groupby_df['Number of Trending Videos'][5:].sum()]\n",
    "}).set_index(\"Category\")\n",
    "\n",
    "# Combined the top 5 with the others.\n",
    "top_trending_categories_us = pd.concat([top_5_categories_us, new_row_us])\n",
    "top_trending_categories_ous = pd.concat([top_5_categories_ous, new_row_ous])\n",
    "\n",
    "# Print the results.\n",
    "print('-------------------------------------------------------')\n",
    "print('Top trending videos by category for OUS')\n",
    "print(top_trending_categories_ous)\n",
    "print('-------------------------------------------------------')\n",
    "print('Top trending videos by category for US')\n",
    "print(top_trending_categories_us)\n",
    "print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top trending videos by category for OUS and US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two pie charts. One that shows the top trending videos by category for US. Other for OUS (Outside of US).\n",
    "# The colors of each section of the pie chart.\n",
    "# OUS\n",
    "number_of_colors_ous = len(top_trending_categories_ous)\n",
    "colors_ous = random.choices(list(mcolors.TABLEAU_COLORS.values()),k = number_of_colors_ous)\n",
    "# US\n",
    "number_of_colors_us = len(top_trending_categories_us)\n",
    "colors_us = random.choices(list(mcolors.BASE_COLORS.values()),k = number_of_colors_us)\n",
    "\n",
    "# Specify the sizes and labels for the pie chart.\n",
    "# OUS\n",
    "sizes_ous = list(top_trending_categories_ous.loc[:, \"Number of Trending Videos\"])\n",
    "labels_ous = list(top_trending_categories_ous.index.values)\n",
    "# US\n",
    "sizes_us = list(top_trending_categories_us.loc[:, \"Number of Trending Videos\"])\n",
    "labels_us = list(top_trending_categories_us.index.values)\n",
    "\n",
    "# Creat plot for OUS.\n",
    "plt.figure(0)\n",
    "\n",
    "# explosion\n",
    "explode = (0.07,0,0,0,0,0)\n",
    "\n",
    "# Create pie chart.\n",
    "plt.pie(sizes_ous, colors=colors_ous, labels=labels_ous, autopct='%1.1f%%', startangle=90,  pctdistance=1.2, labeldistance=1.4, explode=explode, shadow=True)\n",
    "\n",
    "# Make a donut chart.\n",
    "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "# Equal axis\n",
    "plt.axis('equal') \n",
    "\n",
    "# Add a title.\n",
    "plt.title(\"Top Trending Videos By Category (OUS)\")\n",
    "plt.suptitle(\"Exhibit 1\")\n",
    "\n",
    "# Add a legend.\n",
    "plt.legend(bbox_to_anchor=(1.025,1.10), loc=\"upper left\")\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(\"./Images/top_trending_videos_by_category_ous.png\", bbox_inches='tight')\n",
    "\n",
    "# Create plot for US.\n",
    "plt.figure(1)\n",
    "\n",
    "# explosion\n",
    "explode = (0.07,0,0,0,0,0)\n",
    "\n",
    "# Create pie chart.\n",
    "plt.pie(sizes_us, colors=colors_us, labels=labels_us, autopct='%1.1f%%', startangle=90,  pctdistance=1.2, labeldistance=1.4, explode=explode, shadow=True)\n",
    "\n",
    "# Make a donut chart.\n",
    "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "# Equal axis\n",
    "plt.axis('equal') \n",
    "\n",
    "# Add a title.\n",
    "plt.title(\"Top Trending Videos By Category (US)\")\n",
    "plt.suptitle(\"Exhibit 2\")\n",
    "\n",
    "\n",
    "# Add a legend.\n",
    "plt.legend(bbox_to_anchor=(1.025,1.10), loc=\"upper left\")\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(\"./Images/top_trending_videos_by_category_us.png\", bbox_inches='tight')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure Analysis: Trending Videos by Category \n",
    "\n",
    "### Exhibit 1\n",
    " \n",
    "* This figure represents which YouTube category is most popular for non-US viewers, according to the trending videos lise. As shown by the figure, the most dominant category for trending videos in countries outside of the US is the \"Entertainment\" category. Followed by the \"People & Blogs\" and \"News & Politics\" as the second and third most popular categories, respectively. Interestingly, there is no category that consumes the majority (50 percent or more) of the trending videos list for countries outside of the US. The figure shows a diverse collection of categories considering the addition of \"Others\", which includes 26 additional categories outside of the top five displayed above in Exhibit 1.\n",
    "     \n",
    "### Exhibit 2\n",
    "\n",
    "* This figure represents which YouTube category is the most popular for US viewers, according to the trending videos list. As shown by the figure, the most dominant category for trending videos in the US is the \"Entertainment\" category. The second and third most popular US trending video categories are \"Music\" and \"How-to & Style\", respectively. No single category consumes the majority (50 percent or more) of the trending videos list for the US. A diverse collection of category viewership is shown in the figure with the \"Others\" category making up more than one third of the viewership. The \"Others\" category in the US includes 38 additional categories outside of the top five displayed above in Exhibit 2. \n",
    "     \n",
    "**Comparative Analysis**\n",
    "\n",
    "* Comparing Exhibit 1 and Exhibit 2 shows that the US and other countries may have similar YouTube viewership. Most notably these figures show that the top category in the world is \"Entertainment\". Other categories that appear in both top five category lists are \"News and Politics\" and \"Comedy\". Another useful comparison is found in the \"Others\" category. Both exhibits show that more than thirty percent of viewership for trending videos comes from \"Others\". This shows evidence of a large variety of viewership by category across every country. \n",
    "\n",
    "**Considerations and Summarized Findings**\n",
    "\n",
    "* YouTube category is selected by the video creators. Due to this, YouTube has little control over how videos are categorized by their site. As a result, certain categories may find overlap between one category and another. An example of this overlap would be between the US video categories \"Video Blogging\" and \"People and Blogs\". In future studies of YouTube trending videos, a grouping of the category list may prove to be useful and may result in a more precise look at which grouped category is the most popular among trending videos. \n",
    "\n",
    "* _YouTube trending video viewership is highly varied and category may not determine trending success_\n",
    "* _Comparing the US and other countries shows that \"Entertainment\" is the most popular category worldwide_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does publish time affect  likes and comments and a video's chances of making it on the trending list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find US countries.\n",
    "us_publish_time_df = clean_trending_df.loc[clean_trending_df[\"Country\"] == \"US\"]\n",
    "# Find OUS countries.\n",
    "ous_publish_time_df = clean_trending_df.loc[clean_trending_df[\"Country\"] != \"US\"]\n",
    "\n",
    "# Only include columns we need.\n",
    "us_publish_time_df = us_publish_time_df[[\"Video ID\", \"Likes\", \"Comment Count\", \"Publish Time\"]]\n",
    "ous_publish_time_df = ous_publish_time_df[[\"Video ID\", \"Likes\", \"Comment Count\", \"Publish Time\"]]\n",
    "\n",
    "# Calculate total number of comments and likes for each video.\n",
    "# US\n",
    "total_number_likes_comments_us = (us_publish_time_df[\"Likes\"] + us_publish_time_df[\"Comment Count\"])\n",
    "us_publish_time_df[\"Total Number of Likes and Comments\"] = total_number_likes_comments_us\n",
    "# OUS\n",
    "total_number_likes_comments_ous = (ous_publish_time_df[\"Likes\"] + ous_publish_time_df[\"Comment Count\"])\n",
    "ous_publish_time_df[\"Total Number of Likes and Comments\"] = total_number_likes_comments_ous\n",
    "\n",
    "# Time Conversion\n",
    "# US\n",
    "us_publish_time_df[\"Publish Time\"] = pd.to_datetime(us_publish_time_df['Publish Time'], dayfirst=True).dt.strftime('%I:%M %p')\n",
    "us_publish_time_df[\"Publish Time\"] = pd.to_datetime(us_publish_time_df[\"Publish Time\"])\n",
    "# OUS\n",
    "ous_publish_time_df[\"Publish Time\"] = pd.to_datetime(ous_publish_time_df['Publish Time'], dayfirst=True).dt.strftime('%I:%M %p')\n",
    "ous_publish_time_df[\"Publish Time\"] = pd.to_datetime(ous_publish_time_df[\"Publish Time\"])\n",
    "\n",
    "hours = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "us_publish_time_df = us_publish_time_df.set_index(\"Publish Time\")\n",
    "ous_publish_time_df = ous_publish_time_df.set_index(\"Publish Time\")\n",
    "\n",
    "# Function to get average number of likes and comments for videos within specific ranges of time (i.e., 1 hour).\n",
    "def binTime(times, df):\n",
    "    number_likes_comments_time_of_day = []\n",
    "    number_trending_videos_time_of_day = []\n",
    "    for time in times:\n",
    "        time_bin = df.between_time(f'{time}:00', f'{time}:59')\n",
    "        average_comments_likes = time_bin[\"Total Number of Likes and Comments\"].mean()\n",
    "        number_trending_videos = time_bin[\"Video ID\"].nunique()\n",
    "        number_likes_comments_time_of_day.append(average_comments_likes)\n",
    "        number_trending_videos_time_of_day.append(number_trending_videos)\n",
    "    return number_likes_comments_time_of_day, number_trending_videos_time_of_day\n",
    "\n",
    "us_number_likes_comments, us_trending_videos_time_of_day = binTime(hours, us_publish_time_df)\n",
    "ous_number_likes_comments, ous_trending_videos_time_of_day = binTime(hours, ous_publish_time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create values/bins for x-axis. X-axis labels will be hour increments.\n",
    "x_axis = ['12 am', '1 am', '2 am', '3 am', '4 am', '5 am', '6 am', '7 am', '8 am',\n",
    "          '9 am', '10 am', '11 am', '12 pm', '1 pm', '2 pm', '3 pm', '4 pm', '5 pm',\n",
    "          '6 pm', '7 pm', '8 pm', '9 pm', '10 pm', '11 pm']\n",
    "\n",
    "# Put time of day, average number of likes and comments, and number of trending videos into a dataframe.\n",
    "us_time_of_day_df = pd.DataFrame({\n",
    "    \"Time of Day\": x_axis,\n",
    "    \"Average Number of Likes and Comments\": us_number_likes_comments,\n",
    "    \"Number of Trending Videos\": us_trending_videos_time_of_day\n",
    "})\n",
    "\n",
    "# Set index to time of day (this will be the x axis).\n",
    "us_time_of_day_df = us_time_of_day_df.set_index(\"Time of Day\")\n",
    "\n",
    "# Create matplotlib figure\n",
    "fig = plt.figure()\n",
    "\n",
    "# Create matplotlib axes\n",
    "ax = fig.add_subplot(111)\n",
    "# Create another axes that shares the same x-axis as ax.\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# Set the background color of the plot.\n",
    "ax.set_facecolor('#A5ACAF35')\n",
    "\n",
    "# Set the width of the bars.\n",
    "width = 0.4\n",
    "\n",
    "# Plot average number of likes and comments.\n",
    "us_time_of_day_df[\"Average Number of Likes and Comments\"].plot(kind='bar', ax=ax, width=width, position=1, figsize=(15,7), color='#002145', alpha=0.6)\n",
    "# Plot number of trending videos on the same plot.\n",
    "us_time_of_day_df[\"Number of Trending Videos\"].plot(kind='bar', ax=ax2, width=width, position=0,  color='#66C010', alpha=1.0)\n",
    "\n",
    "# Rotate the xtick labels.\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "\n",
    "# Give the plot a title.\n",
    "plt.title(\"(US) Average Number of Likes and Comments vs Number of Trending Videos at Different Times of Day\")\n",
    "plt.suptitle(\"Exhibit 3\")\n",
    "\n",
    "# Add labels to y-axes.\n",
    "ax.set_ylabel('Average Number of Likes and Comments')\n",
    "ax2.set_ylabel('Number of Trending Videos')\n",
    "\n",
    "# Add legends.\n",
    "ax.legend([\"Average Number of Likes and Comments\"], loc=\"upper left\");\n",
    "ax2.legend([\"Number of Trending Videos\"], loc=\"upper right\");\n",
    "\n",
    "# Save figure as an image.\n",
    "plt.savefig(\"./Images/time_of_day_us.png\", bbox_inches='tight')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure Analysis: Publish Time and Engagement for Trending YouTube Videos in the US\n",
    "\n",
    "### Exhibit 3\n",
    " \n",
    "* Exhibit 3 shows the engagement (comments, likes, and dislikes) with trending videos compared to time of day as well as the posting time of trending videos for YouTube trending videos in the US. Looking first at engagement, it is clear that the average total engagement for trending videos hovers between fifty thousand and one hundred thousand for a majority of the day. Two outliers include 4am and 9am times which show large increases in engagement averages, up to three hundred thousand at 9am. \n",
    "* Also shown in Exhibit 3 is the number of trending videos based on their time posted in the US. The figure shows a large number of trending videos are posted between 1pm and 10pm, averaging around 500 videos for this time frame. The remaining posting times show an average around 200 videos. \n",
    "\n",
    "**Considerations and Summarized Findings**\n",
    "\n",
    "* The key finding from Exhibit 3 shows that, for US audiences, a majority of videos that result in the trending status are posted in the afternoon, somewhere between 1pm and 10pm. If a YouTube creator was to consider when the best time to post a video would be they might consider one of these times in order to have the best chance at achieving a trending status. Creators might also consider avoiding times early in the morning between 6am and 10am in order to avoid the dip in trending status that occurs during this time. \n",
    "* Alternatively, creators might expect to see the largest portion of engagement in a trending videos early in the morning during the dip in trending status post time noted above. If they do not notice the spike in engagement they should expect relatively steady engagement throughout the day with averages around fifty and one hundred thousand counts of engagement. \n",
    "\n",
    "* _Most trending videos in the US are posted between 1pm and 10pm, this should be a major consideration for creators._\n",
    "* _US engagement should remain relatively constant, with spikes in engagement in the morning at 4am and 9am._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create values/bins for x-axis. X-axis labels will be hour increments.\n",
    "x_axis = ['12 am', '1 am', '2 am', '3 am', '4 am', '5 am', '6 am', '7 am', '8 am',\n",
    "          '9 am', '10 am', '11 am', '12 pm', '1 pm', '2 pm', '3 pm', '4 pm', '5 pm',\n",
    "          '6 pm', '7 pm', '8 pm', '9 pm', '10 pm', '11 pm']\n",
    "\n",
    "# Put time of day, average number of likes and comments, and number of trending videos into a dataframe.\n",
    "ous_time_of_day_df = pd.DataFrame({\n",
    "    \"Time of Day\": x_axis,\n",
    "    \"Average Number of Likes and Comments\": ous_number_likes_comments,\n",
    "    \"Number of Trending Videos\": ous_trending_videos_time_of_day\n",
    "})\n",
    "\n",
    "# Set index to time of day (this will be the x axis).\n",
    "ous_time_of_day_df = ous_time_of_day_df.set_index(\"Time of Day\")\n",
    "\n",
    "# Create matplotlib figure\n",
    "fig = plt.figure()\n",
    "\n",
    "# Create matplotlib axes\n",
    "ax = fig.add_subplot(111)\n",
    "# Create another axes that shares the same x-axis as ax.\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# Set the background color of the plot.\n",
    "ax.set_facecolor('#A5ACAF35')\n",
    "\n",
    "# Set the width of the bars.\n",
    "width = 0.4\n",
    "\n",
    "# Plot average number of likes and comments.\n",
    "ous_time_of_day_df[\"Average Number of Likes and Comments\"].plot(kind='bar', ax=ax, width=width, position=1, figsize=(15,7), color='#002145', alpha=0.6)\n",
    "# Plot number of trending videos on the same plot.\n",
    "ous_time_of_day_df[\"Number of Trending Videos\"].plot(kind='bar', ax=ax2, width=width, position=0,  color='#66C010', alpha=1.0)\n",
    "\n",
    "# Rotate the xtick labels.\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "\n",
    "# Give the plot a title.\n",
    "plt.title(\"(OUS) Average Number of Likes and Comments vs Number of Trending Videos at Different Times of Day\")\n",
    "plt.suptitle(\"Exhibit 4\")\n",
    "\n",
    "# Add labels to y-axes.\n",
    "ax.set_ylabel('Average Number of Likes and Comments')\n",
    "ax2.set_ylabel('Number of Trending Videos')\n",
    "\n",
    "# Add legends.\n",
    "ax.legend([\"Average Number of Likes and Comments\"], loc=\"upper left\");\n",
    "ax2.legend([\"Number of Trending Videos\"], loc=\"upper right\");\n",
    "\n",
    "# Save figure as an image.\n",
    "plt.savefig(\"./Images/time_of_day_ous.png\", bbox_inches='tight')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure Analysis: Publish Time and Engagement for Trending YouTube Videos outside of US\n",
    "\n",
    "### Exhibit 4\n",
    " \n",
    "* Exhibit 4 shows the engagement (comments, likes, and dislikes) with trending videos compared to time of day as well as the posting time of trending videos for YouTube trending videos outside of the US. Looking first at engagement,  the average total engagement for trending videos hovers between twenty thousand and fifty thousand for a majority of the day. Some outliers include 4am, 5am, 9am times which show large increases in engagement averages, peaking at just under one hundred thousand at 4am. In comparing the US and OUS exhibits shown above, the OUS engagement averages are significantly lower than the US engagement averages. Peak engagement average for OUS is just below one hundred thousand while the US peak average engagement is around three hundred thousand, more than three times larger than the OUS average engagement. \n",
    "\n",
    "* Also shown in Exhibit 4 is the number of trending videos based on their time posted for countries OUS. The figure shows a steady increase of trending videos are posted at 8am with six thousand videos, peaking at 4pm with around fourteen thousand videos, and returning to the average at 9pm with fourty thousand videos. Comparing the number of trending videos and their post time to the US averages, it is clear that the OUS averages are more steady throughout the day, but see much higher averages in trending videos, fourteen thousand, versus the US peak of sixhundred. \n",
    "\n",
    "**Considerations and Summarized Findings**\n",
    "\n",
    "* The key findings from Exhibit 4 show that, for OUS audiences, a majority of videos that result in the trending status are posted throughout the day starting at 8am, peaking at 4pm, and tapering off with a return to the average at 9pm. If a YouTube creator OUS was to consider when the best time to post a video would be they might consider posting in this time window during the day. Creators should also consider avoiding times between 10pm and 7am in order to avoid the dip in trending status that occurs during this time. \n",
    "\n",
    "* Alternatively, OUS creators might expect to see the largest portion of engagement in a trending videos early in the morning during the dip in trending status post time noted above. This same pattern is shown in the US engagement averages. If they do not notice the spike in engagement they should expect relatively steady engagement throughout the day with averages around twenty and fourty thousand counts of engagement. \n",
    "\n",
    "* _Most OUS trending videos are posted between 8am and 9pm, posting time is less of a condieration for OUS creators._\n",
    "* _OUS engagement should remain relatively constant, with spikes in engagement in the morning at 4am, 5am and 9am._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the duration of a video affect number of views?\n",
    "\n",
    "* **Team Lead** for this section: Jenna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter to show only US\n",
    "us_data_df = clean_trending_2020_df.loc[clean_trending_2020_df[\"Country\"] == \"US\"]\n",
    "us_data_df.head()\n",
    "\n",
    "#filter to show only the top 5 categories\n",
    "top_categories_us_df = us_data_df.loc[us_data_df[\"Category\"].isin(top_5_categories_us.index.values)]\n",
    "top_categories_us_df\n",
    "\n",
    "#reformat duration from ISO 8601 to seconds, then minutes\n",
    "top_categories_us_df['Duration'] = top_categories_us_df['Duration'].apply(isodate.parse_duration)\n",
    "top_categories_us_df['Duration'] = top_categories_us_df['Duration']/np.timedelta64(1, 's')\n",
    "top_categories_us_df['Duration (min)'] = round(top_categories_us_df['Duration']/60,1)\n",
    "top_categories_us_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for outliers\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Views of Trending YouTube Videos')\n",
    "ax1.set_ylabel('Views (millions)')\n",
    "ax1.boxplot(top_categories_us_df['Views'])\n",
    "plt.show()\n",
    "\n",
    "# Save figure as an image.\n",
    "plt.savefig(\"./Images/us_views_boxplot.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Box Plot for Outliers**\n",
    "\n",
    "* The box and whisker plot shown above is used to help determine what view counts may qualify as outliers. Further analysis is found below on Exhibit 5 which displays a visual that excludes outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cacluate\n",
    "quartiles = top_categories_us_df['Views'].quantile([.25,.5,.75])\n",
    "lowerq = quartiles[0.25]\n",
    "upperq = quartiles[0.75]\n",
    "iqr = upperq-lowerq\n",
    "lower_bound = round(lowerq - (1.5*iqr),2)\n",
    "upper_bound = round(upperq + (1.5*iqr),2)\n",
    "print(f\"Values below {lower_bound} could be outliers.\")\n",
    "print(f\"Values above {upper_bound} could be outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exclude outliers for views from dataframe & scatter plot (allows for a better visual)\n",
    "top_categories_us_df = top_categories_us_df.loc[top_categories_us_df['Views'] < 4552841]\n",
    "top_categories_us_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define axis for a Scatter Plot for views vs duration\n",
    "x_values = top_categories_us_df['Views']\n",
    "y_values = top_categories_us_df['Duration (min)']\n",
    "\n",
    "# Perform a linear regression on temperature vs. latitude\n",
    "(slope, intercept, rvalue, pvalue, stderr) = stats.linregress(x_values, y_values)\n",
    "\n",
    "# Get regression values\n",
    "regress_values = x_values * slope + intercept\n",
    "\n",
    "# Create line equation string\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x +\" + str(round(intercept,2))\n",
    "\n",
    "# Create Plot\n",
    "plt.scatter(x_values,y_values)\n",
    "plt.xlabel('Views')\n",
    "plt.ylabel('Duration (min)')\n",
    "plt.title('Trending YouTube Video Duration vs. Views')\n",
    "plt.suptitle('Exhibit 5')\n",
    "plt.annotate(line_eq,(2000000,40),fontsize=15,color=\"red\")\n",
    "\n",
    "plt.plot(x_values,regress_values,\"r-\")\n",
    "rvalue2 = round(rvalue*rvalue,6)\n",
    "\n",
    "# Print r square value\n",
    "print(f\"The r-squared is: {rvalue2}\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Save figure as an image.\n",
    "plt.savefig(\"./Images/us_duration_views_scatter.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure Analysis: Trending YouTube Video Duration vs. Views\n",
    "### Exhibit 5\n",
    " \n",
    "* Exhibit 5 shows the duration of trending YouTube videos compared to the amount of views that those videos have. As shown by the r-squared value, the data shows a weak correlation between views and duration. \n",
    "\n",
    "**Considerations**\n",
    "\n",
    "* When considering what makes a successful YouTube video that results in the trending status, creators do not necessarily need to follow guidelines for video length. A weak connection was found between the length of the YouTube video and the amount of views that the video has. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How fast a video gets on the trending list after it gets published."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Team Lead** for this section: Jenna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  How do tags (keywords) affect number of views?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most popular tags in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find US trending videos.\n",
    "us_trending_videos_tags = clean_trending_df.loc[clean_trending_df[\"Country\"] == \"US\"]\n",
    "\n",
    "# Only include the columns we really need.\n",
    "us_trending_videos_tags = us_trending_videos_tags[[\"Video ID\", \"Tags\", \"Views\", \"Likes\", \"Comment Count\", \"Category\"]]\n",
    "\n",
    "# This line takes forever run. So, only run it once. And, then comment it out so you don't accidentally run it again.\n",
    "# TODO: Find a more performant way of doing this.\n",
    "tags_by_category_df = pd.concat([pd.Series(row['Category'], row['Tags'].split('|'))              \n",
    "                     for _, row in us_trending_videos_tags.iterrows()]).reset_index()\n",
    "\n",
    "# Rename columns to something more meaningful.\n",
    "tags_by_category_df = tags_by_category_df.rename(columns={\n",
    "    \"index\": \"Tag\",\n",
    "    0: \"Category\"\n",
    "})\n",
    "\n",
    "# Combine very similar tags and replace.\n",
    "tags_by_category_df_replace = tags_by_category_df.replace({\n",
    "    '\"funny video\"': '\"funny\"',\n",
    "    '\"Funny\"': '\"funny\"',\n",
    "    '\"funny videos\"': '\"funny\"',\n",
    "    '\"comedian\"': '\"comedy\"',\n",
    "    '\"Comedy\"': '\"comedy\"',\n",
    "    '\"makeup tutorial\"': '\"makeup\"',\n",
    "    '\"celebrities\"': '\"celebrity\"',\n",
    "    '\"humor\"': '\"funny\"'\n",
    "    \n",
    "})\n",
    "\n",
    "# Find the number of times each tag was used.\n",
    "top_tags_df = pd.DataFrame(tags_by_category_df_replace[\"Tag\"].value_counts())\n",
    "\n",
    "# Get the top 10 tags.\n",
    "top_10_tags_df = top_tags_df[:10]\n",
    "\n",
    "# Rename columns to be something more meaningful\n",
    "top_10_tags_df = top_10_tags_df.rename(columns={\n",
    "    \"Tag\": \"Number of Tags\"\n",
    "})\n",
    "\n",
    "print('-------------------------------------------------------')\n",
    "print('Top 10 tags used in trending videos in 2017 - 2018')\n",
    "print('--------------------------------------------------------')\n",
    "print(top_10_tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for plotting.\n",
    "tags_graph_df = top_10_tags_df\n",
    "\n",
    "# Create matplotlib figure.\n",
    "fig = plt.figure()\n",
    "\n",
    "# Create matplotlib axis.\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Set the background color of the plot.\n",
    "ax.set_facecolor('#333D79FF')\n",
    "\n",
    "# Set the width of the bars.\n",
    "width = 0.4\n",
    "\n",
    "# Plot it.\n",
    "tags_graph_df.plot(kind='bar', ax=ax, figsize=(15, 7), width=width, position=1, color='#FAEBEFFF', alpha=0.6, align=\"center\")\n",
    "\n",
    "\n",
    "# Rotate the xtick labels.\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "\n",
    "# Add values above each bar.\n",
    "for p in ax.patches:\n",
    "    ax.annotate(np.round(p.get_height(),decimals=2),\n",
    "                (p.get_x()+p.get_width()/2., p.get_height()),\n",
    "                ha='center',\n",
    "                va='center',\n",
    "                xytext=(0, 10),\n",
    "                textcoords='offset points',\n",
    "                color='white',\n",
    "                fontsize=13)\n",
    "\n",
    "# Give the plot a title.\n",
    "plt.title(\"Most Popular Video Tags in the US (2017-2018)\")\n",
    "plt.suptitle(\"Exhibit 6\")\n",
    "\n",
    "# Add labels to y-axes.\n",
    "ax.set_ylabel('Number of Times Tag was Used')\n",
    "\n",
    "# Add legends.\n",
    "ax.legend([\"Number of Times Tag was Used\"], loc=\"upper right\");\n",
    "\n",
    "# Save figure as an image.\n",
    "plt.savefig(\"./Images/popular_tags_us_2018.png\", bbox_inches='tight')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure Analysis: Most Popular Video Tags in the US\n",
    "### Exhibit 6\n",
    " \n",
    "* Exhibit 6 shows the most popular tags attached to trending videos in the US. Tags for YouTube videos function as keywords that creators apply to videos prior to publish time. Tags are now shown to users but help drive users to videos with similar tags. As shown above, the \"funny\", \"comedy\", and \"celebrity\" tags are the top three most popular tags for trending videos in the US. Although \"none\" is the fifth most occuring tag it accounts for a small portion of the trending video total count, as shown in Exhibit 12 below. \n",
    "\n",
    "**Considerations**\n",
    "\n",
    "* Tags seem to be an essential tool for guiding users to content that is popular and aligns with their likes. Overall, 6 provides insight in to what types of videos are most popular in the US based on tag rather than what type of tag should be used to collect views. Additionally, not using a tag, which is the fifth highest occurence is misleading as it is such a small portion of the overall total. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top tags by category in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the top 10 tags for a specific category and plot the results.\n",
    "def get_top_tags_for_category(category, df, country):\n",
    "    # Find tags for specific category.\n",
    "    top_tags = df.loc[df[\"Category\"] == category]\n",
    "    \n",
    "    # Find number of times each tag was used.\n",
    "    top_tags_count = top_tags[\"Tag\"].value_counts()\n",
    "    \n",
    "    # Get the top 10 tags that were used for a specific category.\n",
    "    top_10_tags_df = top_tags_count[:10]\n",
    "\n",
    "    # Rename columns to be something more meaningful\n",
    "    top_10_tags_df = top_10_tags_df.rename(columns={\n",
    "        \"Tag\": \"Number of Tags\"\n",
    "    })\n",
    "    \n",
    "    # Create matplotlib figure.\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # Create matplotlib axis.\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # Set the background color of the plot.\n",
    "    ax.set_facecolor('#154733')\n",
    "\n",
    "    # Set the width of the bars.\n",
    "    width = 0.4\n",
    "    \n",
    "    top_10_tags_df.plot(kind='bar', ax=ax, figsize=(10, 3), width=width, position=1, color='#FEE123', alpha=0.6, align=\"center\")\n",
    "\n",
    "    # Rotate the xtick labels.\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "\n",
    "    # Add values above each bar.\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(np.round(p.get_height(),decimals=2),\n",
    "                    (p.get_x()+p.get_width()/2., p.get_height()),\n",
    "                    ha='center',\n",
    "                    va='center',\n",
    "                    xytext=(0, 10),\n",
    "                    textcoords='offset points',\n",
    "                    color='white',\n",
    "                    fontsize=13)\n",
    "\n",
    "    # Give the plot a title.\n",
    "    plt.title(f\"Most Used Tags in {category} ({country})\")\n",
    "\n",
    "    # Add labels to axes.\n",
    "    ax.set_ylabel('Number of Times Tag was Used')\n",
    "    ax.set_xlabel(\"Tag\")\n",
    "    \n",
    "    # Set limits for axes.\n",
    "    ax.set_ylim(0, max(top_10_tags_df)+400)\n",
    "\n",
    "    # Add legends.\n",
    "    ax.legend([\"Number of Times Tag was Used\"], loc=\"upper right\");\n",
    "\n",
    "    # Save figure as an image.\n",
    "    plt.savefig(f\"./Images/top_tags_{category}_{country}.png\", bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the top 5 categories in the United States to get most used tags for each category.\n",
    "categories = list(top_5_categories_us.index.values)\n",
    "\n",
    "for category in categories:\n",
    "    tags_graph = get_top_tags_for_category(category, tags_by_category_df, \"US\")\n",
    "\n",
    "    tags_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure Analysis: Most Popular Tags by Category in the US\n",
    "### Exhibit 6, 7, 8, 9, 10, 11\n",
    " \n",
    "* Exhibit 6 through Exhibit 11 show the most used tags for trending videos based on video category. Findings from the exhibits show which type of subcategory might be most popular among trending videos based on the amount of times a particular tag was used. For example, looking at the \"Music\" category it would be appropriate to conclude that Pop music is the most popular type of music video for US YouTube audiences. \n",
    "\n",
    "* One major consideration to make, given the above exhibits, is the use of tags versus the category label placed on trending YouTube videos. A YouTube video can only belong in one category, but a video in a single category is allowed to apply more than one tag. Given this consideration a creator might apply several tags in order to optimize their audience's potential to find their video based on user video history. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of videos that dont have any tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_videos = videos_with_less_2_million_views[videos_with_less_2_million_views[\"Country\"] == \"US\"]\n",
    "\n",
    "videos_with_no_tags = us_videos[us_videos[\"Tags\"] == \"[none]\"]\n",
    "videos_with_tags = us_videos[us_videos[\"Tags\"] != \"[none]\"]\n",
    "\n",
    "number_of_videos_with_no_tags = videos_with_no_tags[\"Video ID\"].nunique()\n",
    "number_of_videos_with_tags = videos_with_tags[\"Video ID\"].nunique()\n",
    "\n",
    "# The colors of each section of the pie chart\n",
    "colors = [\"#FFB81C\", \"#E31837\"]\n",
    "\n",
    "# labels and sizes for the sections of the pie chart.\n",
    "labels = ['With Tags', 'No Tags']\n",
    "sizes = [number_of_videos_with_tags, number_of_videos_with_no_tags]\n",
    "\n",
    "# Creates the pie chart.\n",
    "# Automatically finds the percentages of each part of the pie chart\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct=\"%1.1f%%\", shadow=False, startangle=140)\n",
    "\n",
    "# Add title\n",
    "plt.title(\"Percentage of videos with no tags\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "# Create donut shaped chart.\n",
    "centre_circle = plt.Circle((0, 0), 0.7, color='white', linewidth=0)\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "# Equal axis\n",
    "plt.axis('equal')\n",
    "\n",
    "# Show plot and save as png image.\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Images/percentage_videos_no_tags.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure Analysis: Trending Videos With Tags vs. No Tags\n",
    "### Exhibit 12\n",
    " \n",
    "* Exhibit 12 displays the percent of trending YouTube videos that use tags versus the percent of trending YouTube videos that do not use tags. As shown in the pie chart, more than ninety five percent of videos use the tags function. A much smaller portion of videos do not use tags but were still able to achieve the trending video status. Referencing Exhibit 6 alongside Exhibit 12, it can be concluded that the use of tags is strongly suggested when creating YouTube content in order to achieve trending status. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the number of tags used for a video to the number of views.\n",
    "videos_with_tags_vs_views = videos_with_tags[[\"Video ID\", \"Tags\", \"Views\", \"Category\", \"Video Title\", \"Likes\"]]\n",
    "\n",
    "videos_with_tags_vs_views[\"Number of Tags\"] = videos_with_tags_vs_views[\"Tags\"].str.strip().str.split('|').apply(len)\n",
    "\n",
    "videos_with_tags_groupby_video_id = videos_with_tags_vs_views.groupby([\"Video ID\"])[\"Views\", \"Number of Tags\"].mean() \n",
    "\n",
    "videos_with_tags_groupby_video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take random sample of size 1000 from 1000 random entries in the dataset.\n",
    "chosen_idx = np.random.choice(1000, replace=False, size=1000)\n",
    "df_trimmed = videos_with_tags_groupby_video_id.iloc[chosen_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create linear regression plots.\n",
    "def createLinearRegressionPlot(x_values, y_values, x_label, y_label, line_placement, ylim=None):\n",
    "    (slope, intercept, rvalue, pvalue, stderr) = stats.linregress(x_values, y_values)\n",
    "\n",
    "    # Get regression values\n",
    "    regress_values = x_values * slope + intercept\n",
    "    \n",
    "    # Create line equation string\n",
    "    line_eq = \"y = \" + str(round(slope,2)) + \"x +\" + str(round(intercept,2))\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    # Create scatter plot\n",
    "    plt.scatter(x_values, y_values, alpha=0.7, color=\"#e600e6\")\n",
    "    \n",
    "    # Hide spines\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    \n",
    "    # Add axes labels\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    \n",
    "    # Set limits for axes (if one is provided)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(0, ylim)\n",
    "        \n",
    "    # Specify date of analysis.\n",
    "    today = datetime.date(datetime.now())\n",
    "    \n",
    "    # Add title for graph.\n",
    "    plt.title(f\"{x_label} vs {y_label} ({today})\")\n",
    "    \n",
    "    # Add linear regression line and line equation to graph.\n",
    "    plt.annotate(line_eq,line_placement,fontsize=15,color=\"red\", zorder=999)\n",
    "    \n",
    "    # Print r square value and correlation value.\n",
    "    print(f\"The r-squared is: {rvalue**2}\")\n",
    "    correlation = st.pearsonr(x_values,y_values)\n",
    "    print(f\"The correlation between both factors is {round(correlation[0],2)}\")\n",
    "    \n",
    "    # Save figure as png image.\n",
    "    plt.savefig(f\"./Images/{x_label}_vs_{y_label}.png\", bbox_inches=\"tight\")\n",
    "    return plt.plot(x_values,regress_values,\"r-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression plot for number of tags vs number of views.\n",
    "x_axis = df_trimmed[\"Number of Tags\"]\n",
    "y_axis = df_trimmed[\"Views\"]\n",
    "createLinearRegressionPlot(x_axis, y_axis, \"Number of Tags\", \"Number of Views\", (50, 400000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of videos in various cities (map)\n",
    "\n",
    "* **Team Lead** for this section: Phil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi Square (Categories)\n",
    "\n",
    "**IF TIME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
